<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Welcome to the WMT 2022 Metrics Shared Task! &middot; WMT22 Metrics Task
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          WMT22 Metrics Task
        </a>
      </h1>
      <p class="lead">This shared task will examine automatic evaluation metrics for machine translation.</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item active" href="/">Metrics Task</a>
      

      
      
        
          
        
      
        
      
        
          
            <a class="sidebar-nav-item" href="/subtasks/challenge/">Challenge Sets Subtask</a>
          
        
      
        
          
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/subtasks/qe/">QE as a Metric</a>
          
        
      
        
      
        
      
      
    </nav>

    <p>&copy; 2022. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <h1 id="welcome-to-the-wmt-2022-metrics-shared-task">Welcome to the WMT 2022 Metrics Shared Task!</h1>

<p class="message">
  This shared task will examine automatic evaluation metrics for machine translation. We will provide you with MT system outputs along with source text and the human reference translations. We are looking for automatic metric scores for translations at the system-level, and segment-level. We will calculate the system-level, and segment-level correlations of your scores with human judgements.<br /><br />

  We invite submissions of <strong>reference-free metrics</strong> in addition to <strong>reference-based metrics</strong>.<br /><br />   
  
  Have questions or suggestions? Feel free to <a href="mailto:wmt22-metric@googlegroups.com">Contact Us</a>!
</p>

<blockquote>
  <p><code class="language-plaintext highlighter-rouge">â—</code> System outputs are already available to score! Please download them from <a href="https://drive.google.com/file/d/1pxRbFemgkwIJByZI-hojpDuetfCUrcO0/view?usp=sharing">here</a>. We included a README and scripts to help you score the data in the correct format. Please adapt these scripts to your metric and send us an email if you have questions.</p>
</blockquote>

<h2 id="metrics-task-important-dates">Metrics Task Important Dates</h2>

<table>
  <thead>
    <tr>
      <th>Â </th>
      <th style="text-align: center">Date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>System outputs ready to download</strong></td>
      <td style="text-align: center"><strong>16th August, 2022</strong></td>
    </tr>
    <tr>
      <td><strong>Submission deadline for metrics task</strong></td>
      <td style="text-align: center"><strong>23th August, 2022â—</strong></td>
    </tr>
    <tr>
      <td>Paper submission deadline to WMT</td>
      <td style="text-align: center">7th September, 2022</td>
    </tr>
    <tr>
      <td>WMT Notification of acceptance</td>
      <td style="text-align: center">9th October, 2022</td>
    </tr>
    <tr>
      <td>WMT Camera-ready deadline</td>
      <td style="text-align: center">16th October, 2022</td>
    </tr>
    <tr>
      <td>Conference</td>
      <td style="text-align: center">7th - 8th December, 2022</td>
    </tr>
  </tbody>
</table>

<h2 id="goals">Goals</h2>

<p>The goals of the shared metrics task are:</p>

<ul>
  <li>To achieve the strongest correlation with human judgement of translation quality over a diverse set of MT systems;</li>
  <li>To illustrate the suitability of an automatic evaluation metric as a surrogate for human evaluation;</li>
  <li>To test robustness of metrics when evaluating domains other than news data;</li>
  <li>To create high quality datasets for developing and evaluating metrics</li>
</ul>

<h2 id="task-description">Task Description</h2>

<p>We will provide you with the source sentences, output of machine translation systems and reference translations.</p>

<ol>
  <li>Official results: Correlation with MQM scores at the sentence and system level for the following language pairs:
    <ul>
      <li>Chinese-English</li>
      <li>English-Russian</li>
      <li>English-German</li>
    </ul>
  </li>
  <li>Secondary Evaluation: Correlation with official WMT Direct Assessment (DA) scores at the sentence and system level.</li>
</ol>

<h3 id="subtasks">Subtasks:</h3>

<ol>
  <li><a href="./subtasks/qe/">QE as a Metric</a>: In this subtask participants have to score machine translation systems without access to reference translations</li>
  <li><a href="./subtasks/challenge/">Challenge Sets</a>: While other participants are worried with building stronger and better metrics, participants of this subtask have to build challengesets that identify where metrics fail!</li>
</ol>

<h2 id="paper-describing-your-metric">Paper Describing Your Metric</h2>
<p>You are invited to submit a short paper (4 to 6 pages) to WMT describing your automatic evaluation metric. Shared task submission description papers are non-archival, and you are not required to submit a paper if you do not want to. If you donâ€™t, we ask that you give an appropriate reference describing your metric that we can cite in the overview paper.</p>

<h2 id="training-data">Training Data</h2>

<p><code class="language-plaintext highlighter-rouge">â—</code> Since data from previous WMT editions might be difficult to navigate we are adding a table with links to download data from previous years. You have new links in the <strong>New: Download links section</strong></p>

<p>The WMT Metrics shared task takes place yearly since 2008. You may want to use data from previous editions to tune/train your metric. The following table provides links to the descriptions, the <em>raw</em> data and the findings papers of the previous editions:</p>

<table>
  <thead>
    <tr>
      <th>year</th>
      <th style="text-align: center">MQM</th>
      <th style="text-align: center">DA system level</th>
      <th style="text-align: center">DA segment level</th>
      <th style="text-align: center">relative ranking</th>
      <th style="text-align: center">paper</th>
      <th style="text-align: center">.bib</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="https://www.statmt.org/wmt21/metrics-task.html">2021</a></td>
      <td style="text-align: center"><a href="https://github.com/google/wmt-mqm-human-evaluation">ğŸ”—</a></td>
      <td style="text-align: center">ğŸ”—</td>
      <td style="text-align: center">ğŸ”—</td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center"><a href="https://statmt.org/wmt21/pdf/2021.wmt-1.73.pdf">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://statmt.org/wmt21/bib/2021.wmt-1.73.bib">ğŸ”—</a></td>
    </tr>
    <tr>
      <td><a href="https://www.statmt.org/wmt20/metrics-task.html">2020</a></td>
      <td style="text-align: center"><a href="https://github.com/google/wmt-mqm-human-evaluation">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt20/results.html">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt20/results.html">ğŸ”—</a></td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center"><a href="https://statmt.org/wmt20/pdf/2020.wmt-1.77.pdf">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://statmt.org/wmt20/bib/2020.wmt-1.77.bib">ğŸ”—</a></td>
    </tr>
    <tr>
      <td><a href="https://www.statmt.org/wmt19/metrics-task.html">2019</a></td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt19/results.html">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt19/results.html">ğŸ”—</a></td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center"><a href="https://statmt.org/wmt19/pdf/53/WMT02.pdf">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://statmt.org/wmt19/bib/53/WMT02.bib">ğŸ”—</a></td>
    </tr>
    <tr>
      <td><a href="https://www.statmt.org/wmt18/metrics-task.html">2018</a></td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt18/results.html">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt18/results.html">ğŸ”—</a></td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center"><a href="https://statmt.org/wmt18/pdf/WMT078.pdf">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://statmt.org/wmt18/bib/WMT078.bib">ğŸ”—</a></td>
    </tr>
    <tr>
      <td><a href="https://www.statmt.org/wmt17/metrics-task.html">2017</a></td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt17/results.html">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt17/results.html">ğŸ”—</a></td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center"><a href="https://statmt.org/wmt17/pdf/WMT55.pdf">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://statmt.org/wmt17/bib/WMT55.bib">ğŸ”—</a></td>
    </tr>
    <tr>
      <td><a href="https://www.statmt.org/wmt16/metrics-task.html">2016</a></td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt16/results.html">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt16/results.html">ğŸ”—</a></td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center"><a href="https://statmt.org/wmt16/pdf/W16-2302.pdf">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://statmt.org/wmt16/bib/W16-2302.bib">ğŸ”—</a></td>
    </tr>
    <tr>
      <td><a href="https://www.statmt.org/wmt15/metrics-task.html">2015</a></td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt15/results.html">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt15/pdf/WMT31.pdf">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt15/bib/WMT31.bib">ğŸ”—</a></td>
    </tr>
    <tr>
      <td><a href="https://www.statmt.org/wmt14/metrics-task.html">2014</a></td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt14/results.html">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt14/pdf/W14-3336.pdf">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt14/bib/W14-3336.bib">ğŸ”—</a></td>
    </tr>
    <tr>
      <td><a href="https://www.statmt.org/wmt13/metrics-task.html">2013</a></td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt13/results.html">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt13/pdf/WMT02.pdf">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt13/bib/WMT02.bib">ğŸ”—</a></td>
    </tr>
    <tr>
      <td><a href="https://www.statmt.org/wmt12/metrics-task.html">2012</a></td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt12/results.html">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt12/pdf/WMT02.pdf">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt12/bib/WMT02.bib">ğŸ”—</a></td>
    </tr>
    <tr>
      <td><a href="https://www.statmt.org/wmt11/metrics-task.html">2011</a></td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt11/results.html">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt11/pdf/WMT03.pdf">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt11/bib/WMT03.bib">ğŸ”—</a></td>
    </tr>
    <tr>
      <td><a href="https://www.statmt.org/wmt10/metrics-task.html">2010</a></td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt10/results.html">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt10/pdf/WMT03.pdf">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt10/bib/WMT03.bib">ğŸ”—</a></td>
    </tr>
    <tr>
      <td><a href="https://www.statmt.org/wmt09/metrics-task.html">2009</a></td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt09/results.html">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt09/pdf/WMT-0901.pdf">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt09/bib/WMT-0901.bib">ğŸ”—</a></td>
    </tr>
    <tr>
      <td><a href="https://www.statmt.org/wmt08/metrics-task.html">2008</a></td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center">Â </td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt08/results.html">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt08/pdf/WMT09.pdf">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://www.statmt.org/wmt08/bib/WMT09.bib">ğŸ”—</a></td>
    </tr>
  </tbody>
</table>

<p>You can use any past yearâ€™s data to tune your metricâ€™s free parameters if it has any for this yearâ€™s submission. Additionally, you can use any past data as a test set to compare the performance of your metric against published results from past years metric participants.</p>

<p>Also, for running the mearure metrics quality, specially new ones, we encourage you to use <a href="https://github.com/google-research/mt-metrics-eval">mt-metrics-eval</a> repo developed by George Foster.</p>

<h4 id="new-download-links">New: Download links</h4>

<h5 id="da-data">DA data:</h5>

<table>
  <thead>
    <tr>
      <th style="text-align: center">year</th>
      <th style="text-align: center">DA</th>
      <th style="text-align: center">relative ranks</th>
      <th style="text-align: center">paper</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">2017</td>
      <td style="text-align: center"><a href="https://unbabel-experimental-data-sets.s3.eu-west-1.amazonaws.com/wmt/2017-da.csv.tar.gz">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://unbabel-experimental-data-sets.s3.eu-west-1.amazonaws.com/wmt/2017-daRR.csv.tar.gz">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://statmt.org/wmt17/pdf/WMT55.pdf">Results of the WMT17 Metrics Shared Task</a></td>
    </tr>
    <tr>
      <td style="text-align: center">2018</td>
      <td style="text-align: center"><a href="https://unbabel-experimental-data-sets.s3.eu-west-1.amazonaws.com/wmt/2018-da.csv.tar.gz">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://unbabel-experimental-data-sets.s3.eu-west-1.amazonaws.com/wmt/2018-daRR.csv.tar.gz">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://statmt.org/wmt18/pdf/WMT078.pdf">Results of the WMT18 Metrics Shared Task</a></td>
    </tr>
    <tr>
      <td style="text-align: center">2019</td>
      <td style="text-align: center"><a href="https://unbabel-experimental-data-sets.s3.eu-west-1.amazonaws.com/wmt/2019-da.csv.tar.gz">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://unbabel-experimental-data-sets.s3.eu-west-1.amazonaws.com/wmt/2019-daRR.csv.tar.gz">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://statmt.org/wmt19/pdf/53/WMT02.pdf">Results of the WMT19 Metrics Shared Task</a></td>
    </tr>
    <tr>
      <td style="text-align: center">2020</td>
      <td style="text-align: center"><a href="https://unbabel-experimental-data-sets.s3.eu-west-1.amazonaws.com/wmt/2020-da.csv.tar.gz">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://unbabel-experimental-data-sets.s3.eu-west-1.amazonaws.com/wmt/2020-daRR.csv.tar.gz">ğŸ”—</a></td>
      <td style="text-align: center"><a href="https://aclanthology.org/2020.wmt-1.77.pdf">Results of the WMT20 Metrics Shared Task</a></td>
    </tr>
  </tbody>
</table>

<p><code class="language-plaintext highlighter-rouge">â—</code>: We are not providing links to the Direct Assessments from 2021 because we found bugs in the scores. We advise participants to avoid using that data. For 2021 you can rely on the MQM annotations below ğŸ‘‡.</p>

<h5 id="mqm-data">MQM data:</h5>

<table>
  <thead>
    <tr>
      <th style="text-align: center">year</th>
      <th style="text-align: center">LP</th>
      <th style="text-align: center">testset</th>
      <th style="text-align: center">paper</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">2020</td>
      <td style="text-align: center"><a href="https://unbabel-experimental-data-sets.s3.eu-west-1.amazonaws.com/wmt/MQM/wmt-ende-newstest2020.csv.tar.gz">en-de ğŸ”—</a></td>
      <td style="text-align: center">Newstest2020</td>
      <td style="text-align: center"><a href="https://aclanthology.org/2021.tacl-1.87.pdf">A Large-Scale Study of Human Evaluation for Machine Translation</a></td>
    </tr>
    <tr>
      <td style="text-align: center">2020</td>
      <td style="text-align: center"><a href="https://unbabel-experimental-data-sets.s3.eu-west-1.amazonaws.com/wmt/MQM/wmt-zhen-newstest2020.csv.tar.gz">zh-en ğŸ”—</a></td>
      <td style="text-align: center">Newstest2020</td>
      <td style="text-align: center"><a href="https://aclanthology.org/2021.tacl-1.87.pdf">A Large-Scale Study of Human Evaluation for Machine Translation</a></td>
    </tr>
    <tr>
      <td style="text-align: center">2021</td>
      <td style="text-align: center"><a href="https://unbabel-experimental-data-sets.s3.eu-west-1.amazonaws.com/wmt/MQM/wmt-enru-newstest2021.csv.tar.gz">en-ru ğŸ”—</a></td>
      <td style="text-align: center">Newstest2021</td>
      <td style="text-align: center"><a href="https://aclanthology.org/2021.wmt-1.73.pdf">Results of the WMT21 Metrics Shared Task</a></td>
    </tr>
    <tr>
      <td style="text-align: center">2021</td>
      <td style="text-align: center"><a href="https://unbabel-experimental-data-sets.s3.eu-west-1.amazonaws.com/wmt/MQM/wmt-ende-newstest2021.csv.tar.gz">en-de ğŸ”—</a></td>
      <td style="text-align: center">Newstest2021</td>
      <td style="text-align: center"><a href="https://aclanthology.org/2021.wmt-1.73.pdf">Results of the WMT21 Metrics Shared Task</a></td>
    </tr>
    <tr>
      <td style="text-align: center">2021</td>
      <td style="text-align: center"><a href="https://unbabel-experimental-data-sets.s3.eu-west-1.amazonaws.com/wmt/MQM/wmt-zhen-newstest2021.csv.tar.gz">zh-en ğŸ”—</a></td>
      <td style="text-align: center">Newstest2021</td>
      <td style="text-align: center"><a href="https://aclanthology.org/2021.wmt-1.73.pdf">Results of the WMT21 Metrics Shared Task</a></td>
    </tr>
    <tr>
      <td style="text-align: center">2021</td>
      <td style="text-align: center"><a href="https://unbabel-experimental-data-sets.s3.eu-west-1.amazonaws.com/wmt/MQM/wmt-enru-tedtalks.csv.tar.gz">en-ru ğŸ”—</a></td>
      <td style="text-align: center">Ted Talks</td>
      <td style="text-align: center"><a href="https://aclanthology.org/2021.wmt-1.73.pdf">Results of the WMT21 Metrics Shared Task</a></td>
    </tr>
    <tr>
      <td style="text-align: center">2021</td>
      <td style="text-align: center"><a href="https://unbabel-experimental-data-sets.s3.eu-west-1.amazonaws.com/wmt/MQM/wmt-ende-tedtalks.csv.tar.gz">en-de ğŸ”—</a></td>
      <td style="text-align: center">Ted Talks</td>
      <td style="text-align: center"><a href="https://aclanthology.org/2021.wmt-1.73.pdf">Results of the WMT21 Metrics Shared Task</a></td>
    </tr>
    <tr>
      <td style="text-align: center">2021</td>
      <td style="text-align: center"><a href="https://unbabel-experimental-data-sets.s3.eu-west-1.amazonaws.com/wmt/MQM/wmt-zhen-tedtalks.csv.tar.gz">zh-en ğŸ”—</a></td>
      <td style="text-align: center">Ted Talks</td>
      <td style="text-align: center"><a href="https://aclanthology.org/2021.wmt-1.73.pdf">Results of the WMT21 Metrics Shared Task</a></td>
    </tr>
  </tbody>
</table>

<p><code class="language-plaintext highlighter-rouge">â—</code>: MQM data for <em>en-de</em> and <em>zh-en</em> was mostly annotated by Google and it ranges -25 to 0 where 0 is a perfect translation and -25 is the worse possible score. On the other hand, <em>en-ru</em> data was annotated by Unbabel and ranges -inf to 100 where 100 is a perfect translation and something below 0 is a bad translation. You can find the original data <a href="https://github.com/google/wmt-mqm-human-evaluation">here</a> with more information about raters, etcâ€¦</p>

<h2 id="test-sets-evaluation-data">Test Sets (Evaluation Data)</h2>

<p>You can download the System outputs from <a href="https://drive.google.com/file/d/1pxRbFemgkwIJByZI-hojpDuetfCUrcO0/view?usp=sharing">here</a></p>

<h3 id="submission-format">Submission Format</h3>

<p>The output of your software should produce scores for the translations either at the system-level or the segment-level (or preferably both).</p>

<p>We release along with the data two python scripts to help you score the data. The scripts should be easy to modify in order to run your metrics. We advise you to use them.</p>

<p>We also provide 3 examples of scored data using BLEU, chrF and COME-QE (for QE-as-a-metric)</p>

<p><strong>Output file format for system-level rankings</strong></p>

<p>The output files for system-level rankings should be called YOURMETRIC.sys.score.gz and formatted as a tab-separated values (TSV) in the following way:</p>

<blockquote>
  <p>METRIC-NAME\tLANG-PAIR\tTESTSET\tDOMAIN\tREFERENCE\tSYSTEM-ID\tSYSTEM-SCORE</p>
</blockquote>

<p>The output files for segment-level scores should be called YOURMETRIC.seg.score.gz and formatted as a tab-separated values (TSV) in the following way:</p>

<blockquote>
  <p>METRIC-NAME\tLANG-PAIR\tTESTSET\tDOMAIN\tDOCUMENT\tREFERENCE\tSYSTEM-ID\tSEGMENT-NUMBER\tSEGMENT-SCORE</p>
</blockquote>

<p>Each field should be delimited by a single tab character.</p>

<p>Where:</p>

<ul>
  <li><strong>METRIC-NAME</strong> is the name of your automatic evaluation metric.</li>
  <li><strong>LANG-PAIR</strong> is the language pair using two letter abbreviations for the languages (de-en for German-English, for example).</li>
  <li><strong>TESTSET</strong> is the ID of the test set (newstest2021, florestest2021, tedtalks or challengeset.</li>
  <li><strong>DOMAIN</strong> is the domain of a given segment. It can be <em>conversation</em>, <em>ecommerce</em>, <em>news</em>, <em>social</em> or <em>all</em>. The domain will only be used for <em>en-de</em>, <em>en-ru</em> and <em>zh-en</em>. For those languages we will look at results for individual domains + concatenation of all domain (<em>all</em>). For all other language pairs the domain should be <em>all</em>.</li>
  <li><strong>DOCUMENT</strong> is the ID of the document. As for the the domain, the document information is only relevant for <em>en-de</em>, <em>en-ru</em> and <em>zh-en</em>. The information about each document and domain can be found in the <code class="language-plaintext highlighter-rouge">metrics_inputs/txt/generaltest2022/metadata</code>.</li>
  <li><strong>REFERENCE</strong> is the ID of the reference (ref-A or ref-B or ref-C or ref-D for reference-based metrics, and src for reference-free metrics</li>
  <li><strong>SYSTEM-ID</strong> is the ID of system being scored (given by the part of the filename for the plain text file, uedin-syntax for example).</li>
  <li><strong>SEGMENT-NUMBER</strong> is the line number starting from 1 of the plain text input files.</li>
  <li><strong>SYSTEM-SCORE</strong> is the score your metric predicts for the particular system.</li>
  <li><strong>SEGMENT-SCORE</strong> is the score your metric predicts for the particular segment.</li>
</ul>

<h4 id="how-to-submit">How to submit:</h4>

<p>Before you submit, please run your scores files through a validation script, which is now available along with the data in the shared folder.</p>

<p>Please enter yourself to <a href="https://docs.google.com/spreadsheets/d/1bj4i5H-fbZJi3H700P56I7kh0_HWeat1GkVq7-M-ij0/edit?usp=sharing">this shared spreadsheet</a> so we can keep track of your submissions.</p>

<p>Submissions should be sent to <a href="mailto:wmt.metrics@gmail.com">wmt.metrics@gmail.com</a> with the subject â€œWMT Metrics submissionâ€.</p>

<p>You are allowed to submit multiple metrics, but we need you to indicate the primary metric in the email. If submitting more than one metric, please share a folder with all your metrics, for example on Google Drive or Dropbox.</p>

<p><strong>Before August 6th (AOE)</strong>, please send us an email with:</p>

<ul>
  <li>a short paragraph to describe your metric;</li>
  <li>a list of resources that your metric needs. For example None, or WordNet, or GIZA++, or word2vec, or BERT;</li>
  <li>if your metric is supervised, then the training and validation datasets. For example, Unsupervised, or WMT21 DA, or MetricsMQM, or proprietary HTER</li>
  <li>a reference so we can cite your metric in the metrics task results paper. If this is a submission to WMT22, please email the name of the paper and the list of authors. Otherwise, send a bibtex reference to a previously published paper or a pre-print (like Arxiv).</li>
</ul>

<h2 id="organization">Organization:</h2>

<ul>
  <li>Markus Freitag, Google Research</li>
  <li>Ricardo Rei, Unbabel and Instituto Superior TÃ©cnico</li>
  <li>Nitika Mathur, University of Melbourne</li>
  <li>Chi-kiu (Jackie) Lo, NRC Canada</li>
  <li>George Foster, Google Research</li>
  <li>Alon Lavie, Unbabel</li>
  <li>Craig Stewart, Unbabel</li>
  <li>Tom Kocmi, Microsoft Research</li>
  <li>AndrÃ© Martins, Unbabel and Instituto Superior TÃ©cnico</li>
  <li>Eleftherios Avramidis, German Research Center for Artificial Intelligence (DFKI)</li>
</ul>

<h2 id="sponsors">Sponsors</h2>

<style>
	.column {
	  float: left;
	  padding: 20px;
	}
	
</style>

<div style="position: relative; width: 700px; height: 100px; min-height: 200px">    
    <div style="position: relative; bottom: 0px;">
	   <div class="column">
	     <img src="/public/css/google.png" height="70px" width="auto" />
	   </div>
	   <div class="column">
	     <img src="/public/css/unbabel.png" height="70px" width="auto" />
	   </div>
	   <div class="column">
	     <img src="/public/css/microsoft.jpeg" height="70px" width="auto" />
	   </div>
	</div>

<div style="position: relative; width: 700px; height: 100px; min-height: 200px">    
    <div style="position: relative; bottom: 0px;">
	   <div class="column">
	     <img src="/public/css/melbourne.png" height="70px" width="auto" />
	   </div>
	   <div class="column">
	     <img src="/public/css/NRC-logo.png" height="70px" width="auto" />
	   </div>
	   <div class="column">
	     <img src="/public/css/IST.png" height="70px" width="auto" />
	   </div>
	   <div class="column">
	     <img src="/public/css/DFKI.jpeg" height="50px" width="auto" />
	   </div>
	</div>
</div></div>

    </div>

  </body>
</html>
